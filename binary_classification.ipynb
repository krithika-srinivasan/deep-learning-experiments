{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "binary_classification.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMDSZ5TcTbRmA0RTFjostmV",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/krithika-srinivasan/deep-learning-experiments/blob/main/binary_classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zVKusD0Gvea2",
        "outputId": "be33f5ae-a475-4bf9-963e-f03178f19e6e"
      },
      "source": [
        "from keras.datasets import imdb\r\n",
        "\r\n",
        "(train_data, train_labels), (test_data, test_labels) = imdb.load_data(num_words = 10000)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<string>:6: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/datasets/imdb.py:159: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  x_train, y_train = np.array(xs[:idx]), np.array(labels[:idx])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/datasets/imdb.py:160: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  x_test, y_test = np.array(xs[idx:]), np.array(labels[idx:])\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145
        },
        "id": "3P7frDsSwgHD",
        "outputId": "81e7ef65-5510-4e36-aa7a-14e6848321cf"
      },
      "source": [
        "#Decode back to english\r\n",
        "word_index = imdb.get_word_index()\r\n",
        "\r\n",
        "reverse_word_index = dict([(value, key) for (key, value) in word_index.items()])\r\n",
        "decoded_review = ' '.join([reverse_word_index.get(i-3, '?') for i in train_data[4]])\r\n",
        "decoded_review"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb_word_index.json\n",
            "1646592/1641221 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"? worst mistake of my life br br i picked this movie up at target for 5 because i figured hey it's sandler i can get some cheap laughs i was wrong completely wrong mid way through the film all three of my friends were asleep and i was still suffering worst plot worst script worst movie i have ever seen i wanted to hit my head up against a wall for an hour then i'd stop and you know why because it felt damn good upon bashing my head in i stuck that damn movie in the ? and watched it burn and that felt better than anything else i've ever done it took american psycho army of darkness and kill bill just to get over that crap i hate you sandler for actually going through with this and ruining a whole day of my life\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jZ9TiRPTznpY"
      },
      "source": [
        "#Convert into a tensor by one-hot encoding\r\n",
        "import numpy as np\r\n",
        "\r\n",
        "def vectorize_sequences(sequence, dimension=10000):\r\n",
        "  results = np.zeros((len(sequence), dimension))\r\n",
        "  for i, sequence in enumerate(sequence):\r\n",
        "    results[i, sequence] = 1\r\n",
        "  return results\r\n",
        "\r\n",
        "x_train = vectorize_sequences(train_data)\r\n",
        "x_test = vectorize_sequences(test_data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lnvqmp6-1FS6"
      },
      "source": [
        "#Convert labels into tensor form\r\n",
        "y_train = np.asarray(train_labels).astype('float32')\r\n",
        "y_test = np.asarray(test_labels).astype('float32')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AgaEagAB5QKo"
      },
      "source": [
        "#Validation set\r\n",
        "x_val = x_train[:10000]\r\n",
        "partial_x_train = x_train[10000:]\r\n",
        "\r\n",
        "y_val = y_train[:10000]\r\n",
        "partial_y_train = y_train[10000:]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "22btYb6K1apf"
      },
      "source": [
        "#Build the network\r\n",
        "from keras import models\r\n",
        "from keras import layers\r\n",
        "from keras import regularizers\r\n",
        "\r\n",
        "model = models.Sequential()\r\n",
        "model.add(layers.Dense(8, kernel_regularizer = regularizers.l2(0.001), activation='relu', input_shape=(10000,)))\r\n",
        "model.add(layers.Dropout(0.5))\r\n",
        "model.add(layers.Dense(8, kernel_regularizer = regularizers.l2(0.001), activation='relu'))\r\n",
        "model.add(layers.Dropout(0.5))\r\n",
        "model.add(layers.Dense(1, activation='sigmoid'))\r\n",
        "\r\n",
        "model.compile(optimizer='rmsprop', loss='mse', metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7fp0hsVb5mMl",
        "outputId": "4ae093f2-87a3-442e-9d58-ec17f6a56a2c"
      },
      "source": [
        "history = model.fit(partial_x_train, partial_y_train, epochs=20, batch_size=512, validation_data=(x_val, y_val))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "30/30 [==============================] - 2s 44ms/step - loss: 0.2499 - accuracy: 0.6022 - val_loss: 0.1951 - val_accuracy: 0.8331\n",
            "Epoch 2/20\n",
            "30/30 [==============================] - 1s 34ms/step - loss: 0.2034 - accuracy: 0.7211 - val_loss: 0.1564 - val_accuracy: 0.8617\n",
            "Epoch 3/20\n",
            "30/30 [==============================] - 1s 34ms/step - loss: 0.1819 - accuracy: 0.7637 - val_loss: 0.1366 - val_accuracy: 0.8789\n",
            "Epoch 4/20\n",
            "30/30 [==============================] - 1s 34ms/step - loss: 0.1671 - accuracy: 0.7823 - val_loss: 0.1252 - val_accuracy: 0.8833\n",
            "Epoch 5/20\n",
            "30/30 [==============================] - 1s 34ms/step - loss: 0.1560 - accuracy: 0.8256 - val_loss: 0.1193 - val_accuracy: 0.8804\n",
            "Epoch 6/20\n",
            "30/30 [==============================] - 1s 36ms/step - loss: 0.1491 - accuracy: 0.8354 - val_loss: 0.1167 - val_accuracy: 0.8809\n",
            "Epoch 7/20\n",
            "30/30 [==============================] - 1s 34ms/step - loss: 0.1403 - accuracy: 0.8512 - val_loss: 0.1130 - val_accuracy: 0.8821\n",
            "Epoch 8/20\n",
            "30/30 [==============================] - 1s 34ms/step - loss: 0.1336 - accuracy: 0.8598 - val_loss: 0.1130 - val_accuracy: 0.8814\n",
            "Epoch 9/20\n",
            "30/30 [==============================] - 1s 35ms/step - loss: 0.1320 - accuracy: 0.8600 - val_loss: 0.1100 - val_accuracy: 0.8851\n",
            "Epoch 10/20\n",
            "30/30 [==============================] - 1s 34ms/step - loss: 0.1266 - accuracy: 0.8685 - val_loss: 0.1094 - val_accuracy: 0.8820\n",
            "Epoch 11/20\n",
            "30/30 [==============================] - 1s 34ms/step - loss: 0.1216 - accuracy: 0.8729 - val_loss: 0.1094 - val_accuracy: 0.8835\n",
            "Epoch 12/20\n",
            "30/30 [==============================] - 1s 34ms/step - loss: 0.1200 - accuracy: 0.8776 - val_loss: 0.1093 - val_accuracy: 0.8813\n",
            "Epoch 13/20\n",
            "30/30 [==============================] - 1s 34ms/step - loss: 0.1151 - accuracy: 0.8884 - val_loss: 0.1104 - val_accuracy: 0.8813\n",
            "Epoch 14/20\n",
            "30/30 [==============================] - 1s 34ms/step - loss: 0.1147 - accuracy: 0.8859 - val_loss: 0.1107 - val_accuracy: 0.8829\n",
            "Epoch 15/20\n",
            "30/30 [==============================] - 1s 34ms/step - loss: 0.1134 - accuracy: 0.8887 - val_loss: 0.1103 - val_accuracy: 0.8825\n",
            "Epoch 16/20\n",
            "30/30 [==============================] - 1s 34ms/step - loss: 0.1103 - accuracy: 0.8978 - val_loss: 0.1109 - val_accuracy: 0.8817\n",
            "Epoch 17/20\n",
            "30/30 [==============================] - 1s 34ms/step - loss: 0.1109 - accuracy: 0.8922 - val_loss: 0.1132 - val_accuracy: 0.8797\n",
            "Epoch 18/20\n",
            "30/30 [==============================] - 1s 34ms/step - loss: 0.1084 - accuracy: 0.8974 - val_loss: 0.1133 - val_accuracy: 0.8796\n",
            "Epoch 19/20\n",
            "30/30 [==============================] - 1s 35ms/step - loss: 0.1065 - accuracy: 0.9030 - val_loss: 0.1123 - val_accuracy: 0.8807\n",
            "Epoch 20/20\n",
            "30/30 [==============================] - 1s 35ms/step - loss: 0.1046 - accuracy: 0.9081 - val_loss: 0.1147 - val_accuracy: 0.8762\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TFu5SD916J7q"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}